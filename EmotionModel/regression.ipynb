{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            date       metrics         Close  count\n",
      "0     2020-01-01 -1.311437e+18   7200.174316   8317\n",
      "1     2020-01-02  1.154228e+13   6985.470215   9861\n",
      "2     2020-01-03 -1.708432e+18   7344.884277  10988\n",
      "3     2020-01-04 -1.145684e+16   7410.656738   9404\n",
      "4     2020-01-05 -7.966623e+23   7411.317383   9094\n",
      "...          ...           ...           ...    ...\n",
      "1242  2023-05-27 -2.412345e+18  26868.353516  12921\n",
      "1243  2023-05-28  3.793781e+17  28085.646484  13341\n",
      "1244  2023-05-29  8.398361e+15  27745.884766  15120\n",
      "1245  2023-05-30 -2.825257e+18  27702.349609  17600\n",
      "1246  2023-05-31  1.731816e+17  27219.658203  17008\n",
      "\n",
      "[1247 rows x 4 columns]\n",
      "1238 1238\n",
      "0 0\n",
      "模型系数: [[ 0.00168244 -0.0073721  -0.00376362 -0.00164101  0.00329096 -0.00582283\n",
      "   0.00409029]]\n",
      "截距: [0.00167102]\n",
      "0.026649741158220757\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "import torch.nn.init as init\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def regression(df:pd.DataFrame,window,time):\n",
    "    df = df[df['Close'].notna()]\n",
    "    df = df[df['metrics'].notna()]\n",
    "\n",
    "\n",
    "    tensor_list = [df['metrics'].values[i:i+window] for i in range(len(df) - window-time)]\n",
    "    X = np.array(tensor_list)\n",
    "    # X = torch.from_numpy(X)\n",
    "\n",
    "    tensor_list = [df['Close'].values[i:i+1] for i in range(window,len(df)-time)]\n",
    "    Y = np.array(tensor_list)\n",
    "    # Y = torch.from_numpy(Y)\n",
    "\n",
    "\n",
    "    tensor_list = [df['metrics'].values[i:i+window] for i in range(len(df) - window-time,len(df) - window)]\n",
    "    X_test = np.array(tensor_list)\n",
    "    # X_test = torch.from_numpy(X_test)\n",
    "\n",
    "    tensor_list = [df['Close'].values[i:i+1] for i in range(len(df)-time,len(df))]\n",
    "    Y_test = np.array(tensor_list)\n",
    "    # Y_test = torch.from_numpy(Y_test)\n",
    "\n",
    "\n",
    "    print(len(X),len(Y))\n",
    "    print(len(X_test),len(Y_test))\n",
    "\n",
    "    # 创建线性回归模型\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # 拟合模型\n",
    "    model.fit(X, Y)\n",
    "\n",
    "    # 打印模型系数\n",
    "    print('模型系数:', model.coef_)  # 斜率\n",
    "    print('截距:', model.intercept_)  # 截距\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    predicted_y = model.predict(X)\n",
    "    # print(predicted_y)\n",
    "\n",
    "\n",
    "    print(np.corrcoef(Y.ravel(), predicted_y.ravel())[0, 1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # # 定义线性回归模型\n",
    "    # class LinearRegression(nn.Module):\n",
    "    #     def __init__(self, input_size):\n",
    "    #         super(LinearRegression, self).__init__()\n",
    "    #         self.linear = nn.Linear(input_size, 1,dtype=torch.float64,bias=False)\n",
    "    #         # init.normal_(self.linear.weight, mean=0, std=0.01)\n",
    "    #         # init.zeros_(self.linear.weight)\n",
    "\n",
    "\n",
    "    #     def forward(self, x):\n",
    "    #         return self.linear(x)\n",
    "\n",
    "    # # 初始化模型\n",
    "    # model = LinearRegression(window)\n",
    "    # # 定义损失函数\n",
    "    # criterion = nn.MSELoss()\n",
    "    # # 定义优化器\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "\n",
    "\n",
    "    # Y_t = Y.numpy().ravel()\n",
    "    # Y_test_t = Y_test.numpy().ravel()\n",
    "\n",
    "\n",
    "    # # 训练模型\n",
    "    # epochs = 50000\n",
    "    # r2_max = 0\n",
    "    # corr = 0\n",
    "    # return_str = ''\n",
    "    # corrs = [[],[]]\n",
    "    # for epoch in range(epochs):\n",
    "    #     model.train()\n",
    "\n",
    "        \n",
    "\n",
    "    #     # 前向传播\n",
    "    #     y_pred = model(X)\n",
    "\n",
    "    #     # 计算损失\n",
    "    #     loss = criterion(y_pred, Y)\n",
    "    #     # 反向传播\n",
    "    #     optimizer.zero_grad()\n",
    "    #     loss.backward()\n",
    "    #     optimizer.step()\n",
    "    #     if (epoch+1) % 1 == 0:\n",
    "            \n",
    "    #         y_pred_t = y_pred.detach().numpy().ravel()\n",
    "    #         correlation_coefficient = np.corrcoef(Y_t, y_pred_t)[0, 1]\n",
    "    #         r2 = r2_score(Y.numpy().ravel(), y_pred.detach().numpy().ravel())\n",
    "\n",
    "    #         model.eval()\n",
    "    #         y_test_pred = model(X_test)\n",
    "    #         y_test_pred_t = y_test_pred.detach().numpy().ravel()\n",
    "    #         correlation_coefficient_test = np.corrcoef(Y_test_t, y_test_pred_t)[0, 1]\n",
    "    #         corrs[0].append(correlation_coefficient_test)\n",
    "    #         corrs[1].append(epoch+1)\n",
    "\n",
    "    #         # correlation_coefficient_test=0\n",
    "    #         if correlation_coefficient > corr:\n",
    "    #             corr = correlation_coefficient\n",
    "    #             return_str = '{:.4f};{:.4f};{:.4f}'.format(loss.item(), r2, correlation_coefficient)\n",
    "    #         if r2 > r2_max:\n",
    "    #             r2_max =r2\n",
    "    #             return_str = '{:.4f};{:.4f};{:.4f}'.format(loss.item(), r2, correlation_coefficient)\n",
    "            \n",
    "            \n",
    "    #         print('Epoch [{}/{}], Loss: {:.4f}, R2 Score: {:.4f}, train: {:.4f},Corr Score: {:.4f}'.format(epoch+1, epochs, loss.item(), r2, correlation_coefficient,correlation_coefficient_test))\n",
    "    #         # print(model.linear.weight)\n",
    "    # # print(model.linear.weight)\n",
    "    # return return_str,model.linear.weight.detach().numpy().ravel(),corrs\n",
    "\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df = pd.read_csv('sentiment_all_feature.csv')\n",
    "# fear = pd.read_csv('Fear_and_Greed_Index.csv')\n",
    "# df = pd.merge(df,fear,left_on='date',right_on='timestamp',how='left')\n",
    "df['metrics'] = df['metrics']\n",
    "print(df)\n",
    "\n",
    "\n",
    "df['Close'] = df['Close'].pct_change()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for window in [7]:\n",
    "    for diff_type in ['pct_change']:\n",
    "        if diff_type == 'pct_change':\n",
    "            df[['metrics']]= scaler.fit_transform(df[['metrics']])\n",
    "            df = df[df['metrics']!=0]\n",
    "            # print(df[df['metrics']==0])\n",
    "            df['metrics'] = df['metrics'].pct_change()\n",
    "\n",
    "        elif diff_type == 'diff':\n",
    "            df['metrics'] = df['metrics'].diff()\n",
    "        elif diff_type == 'log_return':\n",
    "            df[['metrics']]= scaler.fit_transform(df[['metrics']])\n",
    "            \n",
    "            df = df[df['metrics']!=0]\n",
    "            df['metrics'] = np.log(df['metrics']) - np.log(df['metrics'].shift(1))\n",
    "        else:\n",
    "            df['metrics'] = df['metrics']\n",
    "\n",
    "        # 加入发推量\n",
    "        # df[['count']]= scaler.fit_transform(df[['count']])\n",
    "        # df['metrics'] = df['metrics'] * df['count']\n",
    "\n",
    "\n",
    "        regression(df, window,0)\n",
    "        # res,param,corrs = regression(df, window,0)\n",
    "        # import matplotlib.pyplot as plt\n",
    "        # plt.plot(corrs[1], corrs[0],label='Corr')\n",
    "        # plt.xlabel('Epoth')\n",
    "        # plt.ylabel('Test Corr')\n",
    "        # plt.legend()\n",
    "        # plt.show()\n",
    "        # print(\"{};{};{};{}\".format(window, diff_type, res, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 345389816.8179955\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'r2_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Code\\Digital_Research\\EmotionModel\\regression.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Code/Digital_Research/EmotionModel/regression.ipynb#W1sZmlsZQ%3D%3D?line=106'>107</a>\u001b[0m     plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mBTC Price Prediction\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Code/Digital_Research/EmotionModel/regression.ipynb#W1sZmlsZQ%3D%3D?line=107'>108</a>\u001b[0m     \u001b[39m# plt.show()\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Code/Digital_Research/EmotionModel/regression.ipynb#W1sZmlsZQ%3D%3D?line=108'>109</a>\u001b[0m test(\u001b[39m7\u001b[39;49m,data\u001b[39m.\u001b[39;49mcopy())\n",
      "\u001b[1;32md:\\Code\\Digital_Research\\EmotionModel\\regression.ipynb Cell 2\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/Digital_Research/EmotionModel/regression.ipynb#W1sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mMean Squared Error:\u001b[39m\u001b[39m'\u001b[39m, mse)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/Digital_Research/EmotionModel/regression.ipynb#W1sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39m# 计算R2\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Code/Digital_Research/EmotionModel/regression.ipynb#W1sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m r2 \u001b[39m=\u001b[39m r2_score(test_data, predictions)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/Digital_Research/EmotionModel/regression.ipynb#W1sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mR2 Score:\u001b[39m\u001b[39m'\u001b[39m, r2)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/Digital_Research/EmotionModel/regression.ipynb#W1sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39m# 计算Corr\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'r2_score' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# 读取CSV文件\n",
    "data = pd.read_csv(\"sentiment.csv\")\n",
    "\n",
    "# 提取\"Close\"和\"metrics\"列数据\n",
    "\n",
    "\n",
    "def test(lags,data):\n",
    "    price = data[\"Close\"]\n",
    "    metrics = data[\"metrics\"]\n",
    "    # lags = 7\n",
    "    price = price[lags:]\n",
    "\n",
    "    # 创建滞后外生变量的数据集\n",
    "    lagged_metrics = pd.DataFrame()\n",
    "    for lag in range(1, lags+1):\n",
    "        lagged_metrics[f\"metrics_lag{lag}\"] = metrics.shift(lag)\n",
    "\n",
    "    # 将滞后外生变量和原始数据合并\n",
    "    exog_data = pd.concat([lagged_metrics], axis=1)\n",
    "    exog_data = exog_data[exog_data[f'metrics_lag{lags}'].notna()]\n",
    "\n",
    "    # print(exog_data)\n",
    "    # print(price)\n",
    "\n",
    "\n",
    "    time = 500\n",
    "    train_data = price[:-time]\n",
    "    test_data = price[-time:]\n",
    "    train_sentiment = exog_data[:-time]\n",
    "    test_sentiment = exog_data[-time:]\n",
    "\n",
    "\n",
    "    # print(len(train_data),len(train_sentiment))\n",
    "    # print(len(test_data),len(test_sentiment))\n",
    "\n",
    "    # print(test_data.values)\n",
    "    # 创建并拟合AutoReg模型\n",
    "    add_sentiment = 0\n",
    "    if not add_sentiment:\n",
    "        model = AutoReg(train_data.values, lags=lags)\n",
    "    else:\n",
    "        model = AutoReg(train_data.values, lags=lags,exog=train_sentiment.values)\n",
    "    model_fit = model.fit()\n",
    "\n",
    "\n",
    "    # 预测未来100个时间点的股价\n",
    "    if add_sentiment:\n",
    "        predictions = model_fit.predict(start=len(train_data), end=len(train_data)+len(test_data)-1,exog_oos=test_sentiment.values)\n",
    "    else:\n",
    "        predictions = model_fit.predict(start=len(train_data), end=len(train_data)+len(test_data)-1)\n",
    "    # 计算预测结果的均方误差\n",
    "    # print(predictions.values)\n",
    "    mse = mean_squared_error(test_data, predictions)\n",
    "    print('Mean Squared Error:', mse)\n",
    "    # 计算R2\n",
    "    r2 = r2_score(test_data, predictions)\n",
    "    print('R2 Score:', r2)\n",
    "    # 计算Corr\n",
    "    correlation = np.corrcoef(test_data, predictions)[0, 1]\n",
    "    print(correlation)\n",
    "    # 绘制预测结果\n",
    "\n",
    "    # plt.plot(train_data.index, train_data.values, label='Train Data')\n",
    "    plt.plot(test_data.index, test_data.values, label='Test Data')\n",
    "    plt.plot(test_data.index, predictions, label='Predictions')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Close Price')\n",
    "    plt.title('Stock Price Prediction')\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    add_sentiment = 1\n",
    "    if not add_sentiment:\n",
    "        model = AutoReg(train_data.values, lags=lags)\n",
    "    else:\n",
    "        model = AutoReg(train_data.values, lags=lags,exog=train_sentiment.values)\n",
    "    model_fit = model.fit()\n",
    "\n",
    "\n",
    "    # 预测未来100个时间点的股价\n",
    "    if add_sentiment:\n",
    "        predictions = model_fit.predict(start=len(train_data), end=len(train_data)+len(test_data)-1,exog_oos=test_sentiment.values)\n",
    "    else:\n",
    "        predictions = model_fit.predict(start=len(train_data), end=len(train_data)+len(test_data)-1)\n",
    "    # 计算预测结果的均方误差\n",
    "    # print(predictions.values)\n",
    "    mse = mean_squared_error(test_data, predictions)\n",
    "    print('Mean Squared Error:', mse)\n",
    "    # 计算R2\n",
    "    r2 = r2_score(test_data, predictions)\n",
    "    print('R2 Score:', r2)\n",
    "    # 计算Corr\n",
    "    correlation = np.corrcoef(test_data, predictions)[0, 1]\n",
    "    print(correlation)\n",
    "    # 绘制预测结果\n",
    "    # plt.plot(train_data.index, train_data.values, label='Train Data')\n",
    "    # plt.plot(test_data.index, test_data.values, label='Test Data')\n",
    "    plt.plot(test_data.index, predictions, label='Predictions')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Close Price')\n",
    "    plt.title('BTC Price Prediction')\n",
    "    # plt.show()\n",
    "test(7,data.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "# 读取CSV文件\n",
    "data = pd.read_csv(\"sentiment_.csv\")\n",
    "data['Close'] = data['Close'].pct_change()\n",
    "\n",
    "\n",
    "\n",
    "# 加入发推量\n",
    "# data[['count']]= scaler.fit_transform(data[['count']])\n",
    "# data['metrics'] = data['metrics'] * df['count']\n",
    "\n",
    "data[['metrics']]= scaler.fit_transform(data[['metrics']])\n",
    "data = data[data['metrics']!=0]\n",
    "data['metrics'] = data['metrics'].pct_change()\n",
    "\n",
    "data = data[data['Close'].notna()]\n",
    "data = data[data['metrics'].notna()]\n",
    "# 提取\"Close\"和\"metrics\"列数据\n",
    "data = data.reset_index(drop=True)\n",
    "# print(data)\n",
    "\n",
    "\n",
    "\n",
    "def test(data,lags,time):\n",
    "    price = data[\"Close\"]\n",
    "    metrics = data['metrics']\n",
    "\n",
    "\n",
    "\n",
    "    # lags = 7\n",
    "    price = price[lags:]\n",
    "\n",
    "    # 创建滞后外生变量的数据集\n",
    "    lagged_metrics = pd.DataFrame()\n",
    "    for lag in range(1, lags+1):\n",
    "        lagged_metrics[f\"metrics_lag{lag}\"] = metrics.shift(lag)\n",
    "\n",
    "    # 将滞后外生变量和原始数据合并\n",
    "    exog_data = pd.concat([lagged_metrics], axis=1)\n",
    "    exog_data = exog_data[exog_data[f'metrics_lag{lags}'].notna()]\n",
    "\n",
    "\n",
    "    # exog_data = exog_data[lags:]\n",
    "\n",
    "    # print(exog_data)\n",
    "    # print(price)\n",
    "\n",
    "\n",
    "    # time = 800\n",
    "    train_data = price[:-time]\n",
    "    test_data = price[-time:]\n",
    "    train_sentiment = exog_data[:-time]\n",
    "    test_sentiment = exog_data[-time:]\n",
    "\n",
    "\n",
    "    add_sentiment = 1\n",
    "    # print(len(train_data),len(train_sentiment))\n",
    "    # 创建并拟合AutoReg模型\n",
    "    if add_sentiment:\n",
    "        model = AutoReg(train_data.values, lags=lags, exog=train_sentiment.values)\n",
    "    else:\n",
    "        model = AutoReg(train_data.values, lags=lags)\n",
    "    model_fit = model.fit()\n",
    "    # print(model_fit.params)\n",
    "\n",
    "    # 预测未来100个时间点的股价\n",
    "    if add_sentiment:\n",
    "        predictions = model_fit.predict(start=len(train_data), end=len(train_data)+len(test_data)-1,exog_oos=test_sentiment.values)\n",
    "    else:\n",
    "        predictions = model_fit.predict(start=len(train_data), end=len(train_data)+len(test_data)-1)\n",
    "    # 计算预测结果的均方误差\n",
    "    # print(predictions.values)\n",
    "    mse = mean_squared_error(test_data, predictions)\n",
    "    # print('Mean Squared Error:', mse)\n",
    "    # 计算R2\n",
    "    r2 = r2_score(test_data, predictions)\n",
    "    # print('R2 Score:', r2)\n",
    "    # 计算Corr\n",
    "    correlation1 = np.corrcoef(test_data, predictions)[0, 1]\n",
    "    # print('Corr:',correlation1)\n",
    "    # 绘制预测结果\n",
    "    # plt.plot(train_data.index, train_data.values, label='Train Data')\n",
    "    # plt.plot(test_data.index, test_data.values, label='Test Data')\n",
    "    # plt.plot(test_data.index, predictions, label='Predictions')\n",
    "    # plt.legend()\n",
    "    # plt.xlabel('Date')\n",
    "    # plt.ylabel('Close Price')\n",
    "    # plt.title('Stock Price Prediction')\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    add_sentiment = 0\n",
    "    # print(len(train_data),len(train_sentiment))\n",
    "    # 创建并拟合AutoReg模型\n",
    "    if add_sentiment:\n",
    "        model = AutoReg(train_data.values, lags=lags, exog=train_sentiment.values)\n",
    "    else:\n",
    "        model = AutoReg(train_data.values, lags=lags)\n",
    "    model_fit = model.fit()\n",
    "\n",
    "\n",
    "    # 预测未来100个时间点的股价\n",
    "    if add_sentiment:\n",
    "        predictions = model_fit.predict(start=len(train_data), end=len(train_data)+len(test_data)-1,exog_oos=test_sentiment.values)\n",
    "    else:\n",
    "        predictions = model_fit.predict(start=len(train_data), end=len(train_data)+len(test_data)-1)\n",
    "    # 计算预测结果的均方误差\n",
    "    # print(predictions.values)\n",
    "    mse = mean_squared_error(test_data, predictions)\n",
    "    # print('Mean Squared Error:', mse)\n",
    "    # 计算R2\n",
    "    r2 = r2_score(test_data, predictions)\n",
    "    # print('R2 Score:', r2)\n",
    "    # 计算Corr\n",
    "    correlation2 = np.corrcoef(test_data, predictions)[0, 1]\n",
    "    # print('Corr:',correlation2)\n",
    "    # 绘制预测结果\n",
    "    # plt.plot(train_data.index, train_data.values, label='Train Data')\n",
    "    # plt.plot(test_data.index, test_data.values, label='Test Data')\n",
    "    # plt.plot(test_data.index, predictions, label='Predictions')\n",
    "    # plt.legend()\n",
    "    # plt.xlabel('Date')\n",
    "    # plt.ylabel('Close Price')\n",
    "    # plt.title('Stock Price Prediction')\n",
    "    # plt.show()\n",
    "    return correlation1,correlation2\n",
    "# corr1,corr2 = test(data.copy(),7,100)\n",
    "corr1_l = []\n",
    "corr2_l = []\n",
    "for i in range(100,1200,100):\n",
    "    corr1,corr2 = test(data.copy(),7,i)\n",
    "    corr1_l.append(corr1)\n",
    "    corr2_l.append(corr2)\n",
    "    print(corr1,corr2)\n",
    "plt.plot(range(100,1200,100), corr1_l, label='add sentiment')\n",
    "plt.plot(range(100,1200,100), corr2_l, label='origin')\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close Price')\n",
    "plt.title('Stock Price Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
